import sys
import os

# --- BLOC MAGIQUE A METTRE TOUT EN HAUT ---

# 1. On prend le chemin du fichier actuel (server.py)
current_path = os.path.abspath(__file__)

# 2. On prend le dossier du fichier (serveur/)
current_dir = os.path.dirname(current_path)

# 3. On remonte d'un cran pour avoir le dossier racine (PROJET/)
parent_dir = os.path.dirname(current_dir)

# 4. On ajoute la racine aux chemins de Python
sys.path.append(parent_dir)

# ------------------------------------------

from utils.WSClient import *

import asyncio
import json
import os
import time
import requests
import RPi.GPIO as GPIO

# ============================================================
# 1. CONFIGURATION MAT√âRIEL & API
# ============================================================

# GPIO Servo
SERVO_PIN = 18
SERVO_NEUTRAL = 7.5
SERVO_LEFT = 2.5     # N√©gatif
SERVO_RIGHT = 12.5   # Positif

# Audio
AUDIO_DEVICE = "plughw:1,0" # √Ä adapter via 'arecord -l'
AUDIO_FILE = "/tmp/recording.wav"
RECORD_SECONDS = 5

# URLs (Adapter selon ton setup : Ollama local, OpenAI, etc.)
LLM_URL = "http://localhost:11434/api/generate"  # Ollama
LLM_MODEL = "llama3"
# Pour le STT (Whisper local ou API externe)
# Ici exemple simple avec SpeechRecognition (pip install SpeechRecognition)
USE_SPEECH_RECOGNITION_LIB = True 

# Dictionnaire de sentiments
SENTIMENT_DICT = {
    "je suis nul": "negative",
    "c'est pas grave, je ferai mieux la prochaine fois": "positive",
    "j'abandonne": "negative",
    "je vais y arriver": "positive",
    "je suis content": "positive",
    "c'est horrible": "negative"
}

# Configuration des Steps (tel que demand√©)
STEPS = [
    {
        "id": 1, 
        "actions": [
            {
                "id": 101, 
                "type": "activity", 
                "name": "Analyse Vocale Sentiment",
                "finished": False
            }
        ], 
        "authorized": False, 
        "finished": False
    },
]

# ============================================================
# 2. FONCTIONS MAT√âRIEL (SERVO & AUDIO)
# ============================================================

def setup_gpio():
    """Initialise le GPIO"""
    GPIO.setmode(GPIO.BCM)
    GPIO.setwarnings(False)
    GPIO.setup(SERVO_PIN, GPIO.OUT)
    pwm = GPIO.PWM(SERVO_PIN, 50)
    pwm.start(SERVO_NEUTRAL)
    return pwm

def cleanup_gpio(pwm):
    """Nettoyage"""
    pwm.stop()
    GPIO.cleanup()

def move_servo(pwm, sentiment):
    """Bouge le servo selon le r√©sultat"""
    print(f"‚öôÔ∏è  Servo Mouvement pour: {sentiment}")
    
    if sentiment == "positive":
        target = SERVO_RIGHT
    elif sentiment == "negative":
        target = SERVO_LEFT
    else:
        target = SERVO_NEUTRAL # Neutre si inconnu
        
    pwm.ChangeDutyCycle(target)
    time.sleep(1.0) # Laisser le temps au servo d'arriver
    
    # Retour au neutre
    pwm.ChangeDutyCycle(SERVO_NEUTRAL)
    time.sleep(0.5)
    pwm.ChangeDutyCycle(0) # Couper le signal pour √©viter le bruit

def record_audio_sync():
    """Enregistrement bloquant (sera ex√©cut√© dans un thread)"""
    print(f"üé§ Enregistrement ({RECORD_SECONDS}s)...")
    cmd = f"arecord -D {AUDIO_DEVICE} -f S16_LE -r 16000 -c 1 -d {RECORD_SECONDS} {AUDIO_FILE} 2>/dev/null"
    os.system(cmd)
    print("‚úÖ Enregistrement termin√©.")
    return AUDIO_FILE

# ============================================================
# 3. INTELLIGENCE (STT & LLM)
# ============================================================

def transcribe_audio_sync(audio_path):
    """Transcription Audio -> Texte"""
    print("üìù Transcription en cours...")
    
    # M√©thode simple avec SpeechRecognition (Google Free API)
    # Sinon faire une requ√™te HTTP vers ton serveur Whisper ici
    import speech_recognition as sr
    recognizer = sr.Recognizer()
    
    try:
        with sr.AudioFile(audio_path) as source:
            audio = recognizer.record(source)
        text = recognizer.recognize_google(audio, language="fr-FR")
        print(f"üó£Ô∏è  Texte entendu : \"{text}\"")
        return text
    except Exception as e:
        print(f"‚ùå Erreur STT: {e}")
        return ""

def analyze_sentiment_sync(text):
    """Requ√™te LLM pour analyser le sentiment"""
    print(f"ü§ñ Analyse LLM pour : \"{text}\"")
    
    dict_str = json.dumps(SENTIMENT_DICT, ensure_ascii=False)
    prompt = f"""Analyse le sentiment de cette phrase prononc√©e : "{text}".
    Utilise ce dictionnaire comme r√©f√©rence de ton : {dict_str}.
    Si la phrase ressemble √† du positif, r√©ponds juste "positive".
    Si c'est n√©gatif, r√©ponds juste "negative".
    Si tu ne sais pas, r√©ponds "unknown".
    R√©ponds UNIQUEMENT par le mot cl√©."""

    payload = {
        "model": LLM_MODEL,
        "prompt": prompt,
        "stream": False
    }

    try:
        # Adapter l'URL et le format selon ton serveur LLM (Ollama, OpenAI, etc)
        response = requests.post(LLM_URL, json=payload, timeout=10)
        if response.status_code == 200:
            result = response.json().get('response', '').strip().lower()
            # Nettoyage basique
            if "positive" in result: return "positive"
            if "negative" in result: return "negative"
            return "unknown"
    except Exception as e:
        print(f"‚ùå Erreur LLM: {e}")
        
    return "unknown"

# ============================================================
# 4. LOGIQUE M√âTIER "ACTIVITY"
# ============================================================

def run_activity_logic(pwm):
    """
    Ex√©cute toute la logique de mani√®re synchrone.
    Sera appel√©e via to_thread pour ne pas bloquer le WebSocket.
    """
    # 1. Enregistrer
    path = record_audio_sync()
    
    # 2. Transcrire
    text = transcribe_audio_sync(path)
    
    if not text:
        print("‚ö†Ô∏è Pas de voix d√©tect√©e.")
        return "no_voice"
        
    # 3. Analyser
    sentiment = analyze_sentiment_sync(text)
    print(f"üí° Sentiment d√©tect√© : {sentiment}")
    
    # 4. Actionner
    move_servo(pwm, sentiment)
    
    return sentiment

# ============================================================
# 5. WEBSOCKET HANDLER
# ============================================================

# Variable globale pour le PWM (pour y acc√©der dans le handler)
pwm_global = None

async def my_action_handler(action: dict, client: WSClient, step_id: int):
    """
    Delegate appel√© par le WSClient quand une action arrive
    """
    global pwm_global
    
    action_id = action.get("id")
    action_type = action.get("type")
    
    print(f"\nüì• Action Re√ßue : {action_type} (ID: {action_id})")

    match action_type:
        case "activity":
            print("‚ñ∂Ô∏è D√©marrage de l'activit√© Vocale...")
            
            # Ex√©cuter la logique lourde dans un thread s√©par√© pour ne pas couper le WS
            # run_activity_logic contient (Record -> STT -> LLM -> Servo)
            result_sentiment = await asyncio.to_thread(run_activity_logic, pwm_global)
            
            print(f"‚úÖ Activit√© termin√©e. R√©sultat : {result_sentiment}")
            
            # Mettre √† jour l'action locale (optionnel)
            action["finished"] = True
            action["result"] = result_sentiment
            
            # Renvoyer au serveur que c'est fini
            # On adapte selon la m√©thode disponible dans ta classe WSClient
            # Si tu as une m√©thode g√©n√©rique 'send_action_update' ou similaire :
            if hasattr(client, 'send_choice_result'):
                # On d√©tourne send_choice_result pour renvoyer le r√©sultat, 
                # ou tu cr√©es une m√©thode send_action_finished(step_id, action_id, data)
                await client.send_choice_result(step_id, action_id, result_sentiment)
            else:
                print("‚ö†Ô∏è Aucune m√©thode d'envoi trouv√©e sur le client (ex: send_choice_result)")

        case "choice":
            # Ta logique bouton existante...
            pass
            
        case _:
            print(f"‚ö†Ô∏è Type d'action inconnu : {action_type}")

# ============================================================
# 6. MAIN
# ============================================================

async def main():
    global pwm_global
    
    # 1. Init Hardware
    print("üîå Initialisation GPIO...")
    pwm_global = setup_gpio()
    
    # 2. Init Client WS
    client = WSClient(
        url="ws://192.168.10.182:8057/ws",
        client_key="voice_activity_client",
        action_delegate=my_action_handler,
        steps=STEPS
    )
    
    try:
        # 3. Lancer le client
        await client.run()
    except Exception as e:
        print(f"üî• Crash Main: {e}")
    finally:
        # 4. Cleanup
        print("üëã Arr√™t et nettoyage GPIO")
        cleanup_gpio(pwm_global)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass